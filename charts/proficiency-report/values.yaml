application:
  name: "proficiency-report"
  namespace: "gp-pyspark"
  # Can be "scheduled" (ScheduledSparkApplication) or "adhoc" (SparkApplication)
  # Leave blank and the chart will not create anything
  type: ""
  # Only used on "scheduled" application type
  schedule: ""
  file: "local://"
  sparkVersion: "2.4.5"
  arguments: "--your --script arguments"

serviceAccount:
  create: true
  name: "proficiency-report"

# These actually do all the work
executor:
  cores: 1
  instances: 1
  memory: "512m"
  image:
    repository: "gp-docker.gitprime-ops.com/cloud/proficiency-spark"
    tag: "latest"
    pullPolicy: "Always"
  env: []
  database:
    password:
      ref_master: "some-secret-key-ref"
      ref_slave: "some-secret-key-ref"

# Should not need to have more than one instance
driver:
  cores: 1
  instances: 1
  memory: "1024m"
  image:
    repository: "gp-docker.gitprime-ops.com/cloud/proficiency-spark"
    tag: "latest"
    pullPolicy: "Always"
  env: []
  database:
    password:
      ref_master: "some-secret-key-ref"
      ref_slave: "some-secret-key-ref"
